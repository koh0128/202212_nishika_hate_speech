{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[],"machine_shape":"hm","authorship_tag":"ABX9TyMA+/pa5XyaDvpdhGHwlcvw"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"premium"},"cells":[{"cell_type":"code","source":["# ドライブをマウント\n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"57E0Gic7w3xH","executionInfo":{"status":"ok","timestamp":1668324488296,"user_tz":-540,"elapsed":3317,"user":{"displayName":"大橋幸記","userId":"14481296101370409019"}},"outputId":"1315c5bc-6a39-4efe-d273-8d1080f9c0e4"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["# 自身のColab環境によってディレクトリを変更して下さい\n","import os\n","os.chdir(\"/content/drive/MyDrive/ColabNotebooks/nishika/hate_speech/fake_1th/1/\")\n","!pip install transformers\n","!pip install colorama\n","!pip install sentencepiece\n","!pip install mojimoji"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ix9KPz8KvqFG","executionInfo":{"status":"ok","timestamp":1668324501075,"user_tz":-540,"elapsed":12790,"user":{"displayName":"大橋幸記","userId":"14481296101370409019"}},"outputId":"f84e408b-b5d2-4c51-fe3e-215709729efc"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.24.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.13.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.1)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.1)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.13.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.10.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.9.24)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: colorama in /usr/local/lib/python3.7/dist-packages (0.4.6)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (0.1.97)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: mojimoji in /usr/local/lib/python3.7/dist-packages (0.0.12)\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"Od2d5AhEvnBL","executionInfo":{"status":"ok","timestamp":1668324501076,"user_tz":-540,"elapsed":13,"user":{"displayName":"大橋幸記","userId":"14481296101370409019"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bPG2n6hsvgyF","executionInfo":{"status":"ok","timestamp":1668324907698,"user_tz":-540,"elapsed":406634,"user":{"displayName":"大橋幸記","userId":"14481296101370409019"}},"outputId":"67da77c1-6836-431d-da9e-d7c0806e11ee"},"outputs":[{"output_type":"stream","name":"stdout","text":["Fakenews-2022-11-13-16-28\n"]},{"output_type":"stream","name":"stderr","text":["Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]},{"output_type":"stream","name":"stdout","text":["          id       source                                               text  \\\n","0  80074aa43     news4vip                  まともに相手されてない人との関係なんて\\nそんな大事にするものか？   \n","1  6378fea6b  livejupiter             最近はアヘアヘQSマンやない？ ｲｲ!(・∀・)+1-0(・Ａ・)ｲｸﾅｲ!   \n","2  c535f5613  livejupiter    日本人として生まれても無能な低学歴って分かったら日本人の権利剥奪して追放すべきやろ\\n甘えるな   \n","3  e76638295  livejupiter   よくよく思えば川上は配布にしたらとんでもなく有能だよな\\nガチャから引いたら圧倒的歓喜レベルやで   \n","4  51e4036bf     newsplus  押井は原作レイプの専門家だから\\n原作マンガの真意を誤解させることに関してはプロだが\\nそれ...   \n","\n","   label  \n","0      0  \n","1      0  \n","2      1  \n","3      0  \n","4      0  \n","          id       source                                               text  \\\n","0  80074aa43     news4vip                  まともに相手されてない人との関係なんて\\nそんな大事にするものか？   \n","1  6378fea6b  livejupiter             最近はアヘアヘQSマンやない？ ｲｲ!(・∀・)+1-0(・Ａ・)ｲｸﾅｲ!   \n","2  c535f5613  livejupiter    日本人として生まれても無能な低学歴って分かったら日本人の権利剥奪して追放すべきやろ\\n甘えるな   \n","3  e76638295  livejupiter   よくよく思えば川上は配布にしたらとんでもなく有能だよな\\nガチャから引いたら圧倒的歓喜レベルやで   \n","4  51e4036bf     newsplus  押井は原作レイプの専門家だから\\n原作マンガの真意を誤解させることに関してはプロだが\\nそれ...   \n","\n","   label  kfold  \n","0      0      1  \n","1      0      3  \n","2      1      1  \n","3      0      2  \n","4      0      0  \n","\u001b[33m====== Fold: 0 ======\u001b[0m\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at microsoft/mdeberta-v3-base were not used when initializing DebertaV2Model: ['mask_predictions.dense.weight', 'mask_predictions.classifier.bias', 'mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.dense.bias', 'mask_predictions.classifier.weight', 'lm_predictions.lm_head.bias', 'mask_predictions.LayerNorm.weight', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.LayerNorm.bias']\n","- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["[INFO] Using GPU: A100-SXM4-40GB\n","\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:02<00:00,  2.59s/it, Epoch=1, LR=1.99e-5, Train_Loss=0.627]\n","100%|██████████| 1/1 [00:00<00:00,  6.54it/s, Epoch=1, LR=1.99e-5, Valid_Loss=0.619]\n"]},{"output_type":"stream","name":"stdout","text":["F1-Score: 0.0\n","f1: 0.0\n","\u001b[34mValidation Acc Improved (0.0 ---> 0.0)\n","Model Saved\u001b[0m\n","\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:00<00:00,  2.10it/s, Epoch=2, LR=1.96e-5, Train_Loss=0.591]\n","100%|██████████| 1/1 [00:00<00:00,  6.39it/s, Epoch=2, LR=1.96e-5, Valid_Loss=0.593]\n"]},{"output_type":"stream","name":"stdout","text":["F1-Score: 0.0\n","f1: 0.0\n","\u001b[34mValidation Acc Improved (0.0 ---> 0.0)\n","Model Saved\u001b[0m\n","\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:00<00:00,  2.14it/s, Epoch=3, LR=1.92e-5, Train_Loss=0.566]\n","100%|██████████| 1/1 [00:00<00:00,  6.38it/s, Epoch=3, LR=1.92e-5, Valid_Loss=0.554]\n"]},{"output_type":"stream","name":"stdout","text":["F1-Score: 0.0\n","f1: 0.0\n","\u001b[34mValidation Acc Improved (0.0 ---> 0.0)\n","Model Saved\u001b[0m\n","\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:00<00:00,  2.13it/s, Epoch=4, LR=1.85e-5, Train_Loss=0.556]\n","100%|██████████| 1/1 [00:00<00:00,  6.39it/s, Epoch=4, LR=1.85e-5, Valid_Loss=0.497]\n"]},{"output_type":"stream","name":"stdout","text":["F1-Score: 0.0\n","f1: 0.0\n","\u001b[34mValidation Acc Improved (0.0 ---> 0.0)\n","Model Saved\u001b[0m\n","\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:00<00:00,  2.13it/s, Epoch=5, LR=1.78e-5, Train_Loss=0.44]\n","100%|██████████| 1/1 [00:00<00:00,  6.36it/s, Epoch=5, LR=1.78e-5, Valid_Loss=0.409]\n"]},{"output_type":"stream","name":"stdout","text":["F1-Score: 0.0\n","f1: 0.0\n","\u001b[34mValidation Acc Improved (0.0 ---> 0.0)\n","Model Saved\u001b[0m\n","\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:00<00:00,  2.15it/s, Epoch=6, LR=1.68e-5, Train_Loss=0.382]\n","100%|██████████| 1/1 [00:00<00:00,  6.16it/s, Epoch=6, LR=1.68e-5, Valid_Loss=0.315]\n"]},{"output_type":"stream","name":"stdout","text":["F1-Score: 0.0\n","f1: 0.0\n","\u001b[34mValidation Acc Improved (0.0 ---> 0.0)\n","Model Saved\u001b[0m\n","\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:00<00:00,  2.08it/s, Epoch=7, LR=1.58e-5, Train_Loss=0.253]\n","100%|██████████| 1/1 [00:00<00:00,  6.26it/s, Epoch=7, LR=1.58e-5, Valid_Loss=0.261]\n"]},{"output_type":"stream","name":"stdout","text":["F1-Score: 0.0\n","f1: 0.0\n","\u001b[34mValidation Acc Improved (0.0 ---> 0.0)\n","Model Saved\u001b[0m\n","\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:00<00:00,  2.11it/s, Epoch=8, LR=1.46e-5, Train_Loss=0.263]\n","100%|██████████| 1/1 [00:00<00:00,  6.24it/s, Epoch=8, LR=1.46e-5, Valid_Loss=0.245]\n"]},{"output_type":"stream","name":"stdout","text":["F1-Score: 0.0\n","f1: 0.0\n","\u001b[34mValidation Acc Improved (0.0 ---> 0.0)\n","Model Saved\u001b[0m\n","\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:00<00:00,  2.15it/s, Epoch=9, LR=1.33e-5, Train_Loss=0.284]\n","100%|██████████| 1/1 [00:00<00:00,  6.27it/s, Epoch=9, LR=1.33e-5, Valid_Loss=0.241]\n"]},{"output_type":"stream","name":"stdout","text":["F1-Score: 0.0\n","f1: 0.0\n","\u001b[34mValidation Acc Improved (0.0 ---> 0.0)\n","Model Saved\u001b[0m\n","\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:00<00:00,  2.15it/s, Epoch=10, LR=1.2e-5, Train_Loss=0.278]\n","100%|██████████| 1/1 [00:00<00:00,  6.32it/s, Epoch=10, LR=1.2e-5, Valid_Loss=0.244]\n"]},{"output_type":"stream","name":"stdout","text":["F1-Score: 0.0\n","f1: 0.0\n","\u001b[34mValidation Acc Improved (0.0 ---> 0.0)\n","Model Saved\u001b[0m\n","\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:00<00:00,  1.92it/s, Epoch=11, LR=1.07e-5, Train_Loss=0.297]\n","100%|██████████| 1/1 [00:00<00:00,  6.28it/s, Epoch=11, LR=1.07e-5, Valid_Loss=0.25]\n"]},{"output_type":"stream","name":"stdout","text":["F1-Score: 0.0\n","f1: 0.0\n","\u001b[34mValidation Acc Improved (0.0 ---> 0.0)\n","Model Saved\u001b[0m\n","\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:00<00:00,  2.09it/s, Epoch=12, LR=9.32e-6, Train_Loss=0.254]\n","100%|██████████| 1/1 [00:00<00:00,  5.88it/s, Epoch=12, LR=9.32e-6, Valid_Loss=0.26]\n"]},{"output_type":"stream","name":"stdout","text":["F1-Score: 0.0\n","f1: 0.0\n","\u001b[34mValidation Acc Improved (0.0 ---> 0.0)\n","Model Saved\u001b[0m\n","\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:00<00:00,  2.10it/s, Epoch=13, LR=7.97e-6, Train_Loss=0.269]\n","100%|██████████| 1/1 [00:00<00:00,  5.98it/s, Epoch=13, LR=7.97e-6, Valid_Loss=0.269]\n"]},{"output_type":"stream","name":"stdout","text":["F1-Score: 0.0\n","f1: 0.0\n","\u001b[34mValidation Acc Improved (0.0 ---> 0.0)\n","Model Saved\u001b[0m\n","\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:00<00:00,  2.09it/s, Epoch=14, LR=6.65e-6, Train_Loss=0.0922]\n","100%|██████████| 1/1 [00:00<00:00,  6.30it/s, Epoch=14, LR=6.65e-6, Valid_Loss=0.275]\n"]},{"output_type":"stream","name":"stdout","text":["F1-Score: 0.0\n","f1: 0.0\n","\u001b[34mValidation Acc Improved (0.0 ---> 0.0)\n","Model Saved\u001b[0m\n","\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:00<00:00,  2.08it/s, Epoch=15, LR=5.4e-6, Train_Loss=0.253]\n","100%|██████████| 1/1 [00:00<00:00,  5.81it/s, Epoch=15, LR=5.4e-6, Valid_Loss=0.28]\n"]},{"output_type":"stream","name":"stdout","text":["F1-Score: 0.0\n","f1: 0.0\n","\u001b[34mValidation Acc Improved (0.0 ---> 0.0)\n","Model Saved\u001b[0m\n","\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:00<00:00,  2.14it/s, Epoch=16, LR=4.23e-6, Train_Loss=0.251]\n","100%|██████████| 1/1 [00:00<00:00,  6.33it/s, Epoch=16, LR=4.23e-6, Valid_Loss=0.283]\n"]},{"output_type":"stream","name":"stdout","text":["F1-Score: 0.0\n","f1: 0.0\n","\u001b[34mValidation Acc Improved (0.0 ---> 0.0)\n","Model Saved\u001b[0m\n","\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:00<00:00,  2.18it/s, Epoch=17, LR=3.17e-6, Train_Loss=0.213]\n","100%|██████████| 1/1 [00:00<00:00,  6.23it/s, Epoch=17, LR=3.17e-6, Valid_Loss=0.285]\n"]},{"output_type":"stream","name":"stdout","text":["F1-Score: 0.0\n","f1: 0.0\n","\u001b[34mValidation Acc Improved (0.0 ---> 0.0)\n","Model Saved\u001b[0m\n","\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:00<00:00,  2.13it/s, Epoch=18, LR=2.24e-6, Train_Loss=0.253]\n","100%|██████████| 1/1 [00:00<00:00,  6.36it/s, Epoch=18, LR=2.24e-6, Valid_Loss=0.287]\n"]},{"output_type":"stream","name":"stdout","text":["F1-Score: 0.0\n","f1: 0.0\n","\u001b[34mValidation Acc Improved (0.0 ---> 0.0)\n","Model Saved\u001b[0m\n","\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:00<00:00,  2.09it/s, Epoch=19, LR=1.46e-6, Train_Loss=0.164]\n","100%|██████████| 1/1 [00:00<00:00,  5.92it/s, Epoch=19, LR=1.46e-6, Valid_Loss=0.287]\n"]},{"output_type":"stream","name":"stdout","text":["F1-Score: 0.0\n","f1: 0.0\n","\u001b[34mValidation Acc Improved (0.0 ---> 0.0)\n","Model Saved\u001b[0m\n","\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:00<00:00,  2.09it/s, Epoch=20, LR=8.28e-7, Train_Loss=0.248]\n","100%|██████████| 1/1 [00:00<00:00,  6.31it/s, Epoch=20, LR=8.28e-7, Valid_Loss=0.288]\n"]},{"output_type":"stream","name":"stdout","text":["F1-Score: 0.0\n","f1: 0.0\n","\u001b[34mValidation Acc Improved (0.0 ---> 0.0)\n","Model Saved\u001b[0m\n","\n","Training complete in 0h 1m 40s\n","Best Acc: 0.0000\n","\n","\u001b[33m====== Fold: 1 ======\u001b[0m\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at microsoft/mdeberta-v3-base were not used when initializing DebertaV2Model: ['mask_predictions.dense.weight', 'mask_predictions.classifier.bias', 'mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.dense.bias', 'mask_predictions.classifier.weight', 'lm_predictions.lm_head.bias', 'mask_predictions.LayerNorm.weight', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.LayerNorm.bias']\n","- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["[INFO] Using GPU: A100-SXM4-40GB\n","\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:00<00:00,  2.27it/s, Epoch=1, LR=1.99e-5, Train_Loss=0.693]\n","100%|██████████| 1/1 [00:00<00:00,  6.99it/s, Epoch=1, LR=1.99e-5, Valid_Loss=0.669]\n"]},{"output_type":"stream","name":"stdout","text":["F1-Score: 0.0\n","f1: 0.0\n","\u001b[34mValidation Acc Improved (0.0 ---> 0.0)\n","Model Saved\u001b[0m\n","\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:00<00:00,  2.24it/s, Epoch=2, LR=1.96e-5, Train_Loss=0.694]\n","100%|██████████| 1/1 [00:00<00:00,  6.00it/s, Epoch=2, LR=1.96e-5, Valid_Loss=0.645]\n"]},{"output_type":"stream","name":"stdout","text":["F1-Score: 0.0\n","f1: 0.0\n","\u001b[34mValidation Acc Improved (0.0 ---> 0.0)\n","Model Saved\u001b[0m\n","\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:00<00:00,  2.26it/s, Epoch=3, LR=1.92e-5, Train_Loss=0.664]\n","100%|██████████| 1/1 [00:00<00:00,  6.61it/s, Epoch=3, LR=1.92e-5, Valid_Loss=0.617]\n"]},{"output_type":"stream","name":"stdout","text":["F1-Score: 0.0\n","f1: 0.0\n","\u001b[34mValidation Acc Improved (0.0 ---> 0.0)\n","Model Saved\u001b[0m\n","\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:00<00:00,  2.23it/s, Epoch=4, LR=1.85e-5, Train_Loss=0.625]\n","100%|██████████| 1/1 [00:00<00:00,  6.77it/s, Epoch=4, LR=1.85e-5, Valid_Loss=0.582]\n"]},{"output_type":"stream","name":"stdout","text":["F1-Score: 0.0\n","f1: 0.0\n","\u001b[34mValidation Acc Improved (0.0 ---> 0.0)\n","Model Saved\u001b[0m\n","\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:00<00:00,  2.29it/s, Epoch=5, LR=1.78e-5, Train_Loss=0.553]\n","100%|██████████| 1/1 [00:00<00:00,  6.70it/s, Epoch=5, LR=1.78e-5, Valid_Loss=0.537]\n"]},{"output_type":"stream","name":"stdout","text":["F1-Score: 0.0\n","f1: 0.0\n","\u001b[34mValidation Acc Improved (0.0 ---> 0.0)\n","Model Saved\u001b[0m\n","\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:00<00:00,  2.25it/s, Epoch=6, LR=1.68e-5, Train_Loss=0.534]\n","100%|██████████| 1/1 [00:00<00:00,  6.09it/s, Epoch=6, LR=1.68e-5, Valid_Loss=0.48]\n"]},{"output_type":"stream","name":"stdout","text":["F1-Score: 0.0\n","f1: 0.0\n","\u001b[34mValidation Acc Improved (0.0 ---> 0.0)\n","Model Saved\u001b[0m\n","\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:00<00:00,  2.27it/s, Epoch=7, LR=1.58e-5, Train_Loss=0.451]\n","100%|██████████| 1/1 [00:00<00:00,  6.32it/s, Epoch=7, LR=1.58e-5, Valid_Loss=0.423]\n"]},{"output_type":"stream","name":"stdout","text":["F1-Score: 0.0\n","f1: 0.0\n","\u001b[34mValidation Acc Improved (0.0 ---> 0.0)\n","Model Saved\u001b[0m\n","\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:00<00:00,  2.26it/s, Epoch=8, LR=1.46e-5, Train_Loss=0.41]\n","100%|██████████| 1/1 [00:00<00:00,  6.67it/s, Epoch=8, LR=1.46e-5, Valid_Loss=0.376]\n"]},{"output_type":"stream","name":"stdout","text":["F1-Score: 0.0\n","f1: 0.0\n","\u001b[34mValidation Acc Improved (0.0 ---> 0.0)\n","Model Saved\u001b[0m\n","\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:00<00:00,  2.25it/s, Epoch=9, LR=1.33e-5, Train_Loss=0.378]\n","100%|██████████| 1/1 [00:00<00:00,  5.96it/s, Epoch=9, LR=1.33e-5, Valid_Loss=0.347]\n"]},{"output_type":"stream","name":"stdout","text":["F1-Score: 0.0\n","f1: 0.0\n","\u001b[34mValidation Acc Improved (0.0 ---> 0.0)\n","Model Saved\u001b[0m\n","\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:00<00:00,  2.25it/s, Epoch=10, LR=1.2e-5, Train_Loss=0.291]\n","100%|██████████| 1/1 [00:00<00:00,  6.73it/s, Epoch=10, LR=1.2e-5, Valid_Loss=0.327]\n"]},{"output_type":"stream","name":"stdout","text":["F1-Score: 0.0\n","f1: 0.0\n","\u001b[34mValidation Acc Improved (0.0 ---> 0.0)\n","Model Saved\u001b[0m\n","\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:02<00:00,  2.28s/it, Epoch=11, LR=1.07e-5, Train_Loss=0.311]\n","100%|██████████| 1/1 [00:00<00:00,  6.23it/s, Epoch=11, LR=1.07e-5, Valid_Loss=0.312]\n"]},{"output_type":"stream","name":"stdout","text":["F1-Score: 0.0\n","f1: 0.0\n","\u001b[34mValidation Acc Improved (0.0 ---> 0.0)\n","Model Saved\u001b[0m\n","\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:00<00:00,  2.19it/s, Epoch=12, LR=9.32e-6, Train_Loss=0.262]\n","100%|██████████| 1/1 [00:00<00:00,  6.63it/s, Epoch=12, LR=9.32e-6, Valid_Loss=0.302]\n"]},{"output_type":"stream","name":"stdout","text":["F1-Score: 0.0\n","f1: 0.0\n","\u001b[34mValidation Acc Improved (0.0 ---> 0.0)\n","Model Saved\u001b[0m\n","\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:00<00:00,  2.18it/s, Epoch=13, LR=7.97e-6, Train_Loss=0.296]\n","100%|██████████| 1/1 [00:00<00:00,  6.81it/s, Epoch=13, LR=7.97e-6, Valid_Loss=0.295]\n"]},{"output_type":"stream","name":"stdout","text":["F1-Score: 0.0\n","f1: 0.0\n","\u001b[34mValidation Acc Improved (0.0 ---> 0.0)\n","Model Saved\u001b[0m\n","\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:00<00:00,  2.35it/s, Epoch=14, LR=6.65e-6, Train_Loss=0.271]\n","100%|██████████| 1/1 [00:00<00:00,  6.82it/s, Epoch=14, LR=6.65e-6, Valid_Loss=0.292]\n"]},{"output_type":"stream","name":"stdout","text":["F1-Score: 0.0\n","f1: 0.0\n","\u001b[34mValidation Acc Improved (0.0 ---> 0.0)\n","Model Saved\u001b[0m\n","\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:00<00:00,  2.21it/s, Epoch=15, LR=5.4e-6, Train_Loss=0.259]\n","100%|██████████| 1/1 [00:00<00:00,  6.63it/s, Epoch=15, LR=5.4e-6, Valid_Loss=0.289]\n"]},{"output_type":"stream","name":"stdout","text":["F1-Score: 0.0\n","f1: 0.0\n","\u001b[34mValidation Acc Improved (0.0 ---> 0.0)\n","Model Saved\u001b[0m\n","\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:00<00:00,  2.26it/s, Epoch=16, LR=4.23e-6, Train_Loss=0.199]\n","100%|██████████| 1/1 [00:00<00:00,  6.64it/s, Epoch=16, LR=4.23e-6, Valid_Loss=0.288]\n"]},{"output_type":"stream","name":"stdout","text":["F1-Score: 0.0\n","f1: 0.0\n","\u001b[34mValidation Acc Improved (0.0 ---> 0.0)\n","Model Saved\u001b[0m\n","\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:00<00:00,  2.26it/s, Epoch=17, LR=3.17e-6, Train_Loss=0.193]\n","100%|██████████| 1/1 [00:00<00:00,  6.77it/s, Epoch=17, LR=3.17e-6, Valid_Loss=0.287]\n"]},{"output_type":"stream","name":"stdout","text":["F1-Score: 0.0\n","f1: 0.0\n","\u001b[34mValidation Acc Improved (0.0 ---> 0.0)\n","Model Saved\u001b[0m\n","\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:00<00:00,  2.28it/s, Epoch=18, LR=2.24e-6, Train_Loss=0.249]\n","100%|██████████| 1/1 [00:00<00:00,  6.63it/s, Epoch=18, LR=2.24e-6, Valid_Loss=0.287]\n"]},{"output_type":"stream","name":"stdout","text":["F1-Score: 0.0\n","f1: 0.0\n","\u001b[34mValidation Acc Improved (0.0 ---> 0.0)\n","Model Saved\u001b[0m\n","\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:00<00:00,  2.30it/s, Epoch=19, LR=1.46e-6, Train_Loss=0.252]\n","100%|██████████| 1/1 [00:00<00:00,  6.59it/s, Epoch=19, LR=1.46e-6, Valid_Loss=0.287]\n"]},{"output_type":"stream","name":"stdout","text":["F1-Score: 0.0\n","f1: 0.0\n","\u001b[34mValidation Acc Improved (0.0 ---> 0.0)\n","Model Saved\u001b[0m\n","\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:00<00:00,  2.27it/s, Epoch=20, LR=8.28e-7, Train_Loss=0.261]\n","100%|██████████| 1/1 [00:00<00:00,  6.59it/s, Epoch=20, LR=8.28e-7, Valid_Loss=0.287]\n"]},{"output_type":"stream","name":"stdout","text":["F1-Score: 0.0\n","f1: 0.0\n","\u001b[34mValidation Acc Improved (0.0 ---> 0.0)\n","Model Saved\u001b[0m\n","\n","Training complete in 0h 1m 38s\n","Best Acc: 0.0000\n","\n","\u001b[33m====== Fold: 2 ======\u001b[0m\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at microsoft/mdeberta-v3-base were not used when initializing DebertaV2Model: ['mask_predictions.dense.weight', 'mask_predictions.classifier.bias', 'mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.dense.bias', 'mask_predictions.classifier.weight', 'lm_predictions.lm_head.bias', 'mask_predictions.LayerNorm.weight', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.LayerNorm.bias']\n","- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["[INFO] Using GPU: A100-SXM4-40GB\n","\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:00<00:00,  2.24it/s, Epoch=1, LR=1.99e-5, Train_Loss=0.681]\n","100%|██████████| 1/1 [00:00<00:00,  6.15it/s, Epoch=1, LR=1.99e-5, Valid_Loss=0.66]\n"]},{"output_type":"stream","name":"stdout","text":["F1-Score: 0.0\n","f1: 0.0\n","\u001b[34mValidation Acc Improved (0.0 ---> 0.0)\n","Model Saved\u001b[0m\n","\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:00<00:00,  2.29it/s, Epoch=2, LR=1.96e-5, Train_Loss=0.696]\n","100%|██████████| 1/1 [00:00<00:00,  6.77it/s, Epoch=2, LR=1.96e-5, Valid_Loss=0.614]\n"]},{"output_type":"stream","name":"stdout","text":["F1-Score: 0.0\n","f1: 0.0\n","\u001b[34mValidation Acc Improved (0.0 ---> 0.0)\n","Model Saved\u001b[0m\n","\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:00<00:00,  2.26it/s, Epoch=3, LR=1.92e-5, Train_Loss=0.621]\n","100%|██████████| 1/1 [00:00<00:00,  6.40it/s, Epoch=3, LR=1.92e-5, Valid_Loss=0.538]\n"]},{"output_type":"stream","name":"stdout","text":["F1-Score: 0.0\n","f1: 0.0\n","\u001b[34mValidation Acc Improved (0.0 ---> 0.0)\n","Model Saved\u001b[0m\n","\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:00<00:00,  2.23it/s, Epoch=4, LR=1.85e-5, Train_Loss=0.565]\n","100%|██████████| 1/1 [00:00<00:00,  6.52it/s, Epoch=4, LR=1.85e-5, Valid_Loss=0.458]\n"]},{"output_type":"stream","name":"stdout","text":["F1-Score: 0.0\n","f1: 0.0\n","\u001b[34mValidation Acc Improved (0.0 ---> 0.0)\n","Model Saved\u001b[0m\n","\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:00<00:00,  2.34it/s, Epoch=5, LR=1.78e-5, Train_Loss=0.531]\n","100%|██████████| 1/1 [00:00<00:00,  6.86it/s, Epoch=5, LR=1.78e-5, Valid_Loss=0.393]\n"]},{"output_type":"stream","name":"stdout","text":["F1-Score: 0.0\n","f1: 0.0\n","\u001b[34mValidation Acc Improved (0.0 ---> 0.0)\n","Model Saved\u001b[0m\n","\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:00<00:00,  2.31it/s, Epoch=6, LR=1.68e-5, Train_Loss=0.448]\n","100%|██████████| 1/1 [00:00<00:00,  6.83it/s, Epoch=6, LR=1.68e-5, Valid_Loss=0.314]\n"]},{"output_type":"stream","name":"stdout","text":["F1-Score: 0.0\n","f1: 0.0\n","\u001b[34mValidation Acc Improved (0.0 ---> 0.0)\n","Model Saved\u001b[0m\n","\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:00<00:00,  2.27it/s, Epoch=7, LR=1.58e-5, Train_Loss=0.375]\n","100%|██████████| 1/1 [00:00<00:00,  6.66it/s, Epoch=7, LR=1.58e-5, Valid_Loss=0.229]\n"]},{"output_type":"stream","name":"stdout","text":["F1-Score: 0.0\n","f1: 0.0\n","\u001b[34mValidation Acc Improved (0.0 ---> 0.0)\n","Model Saved\u001b[0m\n","\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:00<00:00,  2.20it/s, Epoch=8, LR=1.46e-5, Train_Loss=0.366]\n","100%|██████████| 1/1 [00:00<00:00,  6.77it/s, Epoch=8, LR=1.46e-5, Valid_Loss=0.164]\n"]},{"output_type":"stream","name":"stdout","text":["F1-Score: 0.0\n","f1: 0.0\n","\u001b[34mValidation Acc Improved (0.0 ---> 0.0)\n","Model Saved\u001b[0m\n","\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:00<00:00,  2.24it/s, Epoch=9, LR=1.33e-5, Train_Loss=0.333]\n","100%|██████████| 1/1 [00:00<00:00,  6.18it/s, Epoch=9, LR=1.33e-5, Valid_Loss=0.131]\n"]},{"output_type":"stream","name":"stdout","text":["F1-Score: 0.0\n","f1: 0.0\n","\u001b[34mValidation Acc Improved (0.0 ---> 0.0)\n","Model Saved\u001b[0m\n","\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:00<00:00,  2.35it/s, Epoch=10, LR=1.2e-5, Train_Loss=0.309]\n","100%|██████████| 1/1 [00:00<00:00,  6.65it/s, Epoch=10, LR=1.2e-5, Valid_Loss=0.111]\n"]},{"output_type":"stream","name":"stdout","text":["F1-Score: 0.0\n","f1: 0.0\n","\u001b[34mValidation Acc Improved (0.0 ---> 0.0)\n","Model Saved\u001b[0m\n","\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:00<00:00,  2.26it/s, Epoch=11, LR=1.07e-5, Train_Loss=0.301]\n","100%|██████████| 1/1 [00:00<00:00,  6.80it/s, Epoch=11, LR=1.07e-5, Valid_Loss=0.0976]\n"]},{"output_type":"stream","name":"stdout","text":["F1-Score: 0.0\n","f1: 0.0\n","\u001b[34mValidation Acc Improved (0.0 ---> 0.0)\n","Model Saved\u001b[0m\n","\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:00<00:00,  2.23it/s, Epoch=12, LR=9.32e-6, Train_Loss=0.308]\n","100%|██████████| 1/1 [00:00<00:00,  6.12it/s, Epoch=12, LR=9.32e-6, Valid_Loss=0.0889]\n"]},{"output_type":"stream","name":"stdout","text":["F1-Score: 0.0\n","f1: 0.0\n","\u001b[34mValidation Acc Improved (0.0 ---> 0.0)\n","Model Saved\u001b[0m\n","\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:00<00:00,  2.25it/s, Epoch=13, LR=7.97e-6, Train_Loss=0.278]\n","100%|██████████| 1/1 [00:00<00:00,  6.67it/s, Epoch=13, LR=7.97e-6, Valid_Loss=0.0833]\n"]},{"output_type":"stream","name":"stdout","text":["F1-Score: 0.0\n","f1: 0.0\n","\u001b[34mValidation Acc Improved (0.0 ---> 0.0)\n","Model Saved\u001b[0m\n","\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:00<00:00,  2.31it/s, Epoch=14, LR=6.65e-6, Train_Loss=0.29]\n","100%|██████████| 1/1 [00:00<00:00,  6.69it/s, Epoch=14, LR=6.65e-6, Valid_Loss=0.0805]\n"]},{"output_type":"stream","name":"stdout","text":["F1-Score: 0.0\n","f1: 0.0\n","\u001b[34mValidation Acc Improved (0.0 ---> 0.0)\n","Model Saved\u001b[0m\n","\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:00<00:00,  2.27it/s, Epoch=15, LR=5.4e-6, Train_Loss=0.202]\n","100%|██████████| 1/1 [00:00<00:00,  6.18it/s, Epoch=15, LR=5.4e-6, Valid_Loss=0.0787]\n"]},{"output_type":"stream","name":"stdout","text":["F1-Score: 0.0\n","f1: 0.0\n","\u001b[34mValidation Acc Improved (0.0 ---> 0.0)\n","Model Saved\u001b[0m\n","\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:00<00:00,  2.32it/s, Epoch=16, LR=4.23e-6, Train_Loss=0.202]\n","100%|██████████| 1/1 [00:00<00:00,  6.80it/s, Epoch=16, LR=4.23e-6, Valid_Loss=0.0776]\n"]},{"output_type":"stream","name":"stdout","text":["F1-Score: 0.0\n","f1: 0.0\n","\u001b[34mValidation Acc Improved (0.0 ---> 0.0)\n","Model Saved\u001b[0m\n","\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:00<00:00,  2.23it/s, Epoch=17, LR=3.17e-6, Train_Loss=0.187]\n","100%|██████████| 1/1 [00:00<00:00,  6.83it/s, Epoch=17, LR=3.17e-6, Valid_Loss=0.0769]\n"]},{"output_type":"stream","name":"stdout","text":["F1-Score: 0.0\n","f1: 0.0\n","\u001b[34mValidation Acc Improved (0.0 ---> 0.0)\n","Model Saved\u001b[0m\n","\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:00<00:00,  2.29it/s, Epoch=18, LR=2.24e-6, Train_Loss=0.219]\n","100%|██████████| 1/1 [00:00<00:00,  6.47it/s, Epoch=18, LR=2.24e-6, Valid_Loss=0.0766]\n"]},{"output_type":"stream","name":"stdout","text":["F1-Score: 0.0\n","f1: 0.0\n","\u001b[34mValidation Acc Improved (0.0 ---> 0.0)\n","Model Saved\u001b[0m\n","\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:00<00:00,  2.20it/s, Epoch=19, LR=1.46e-6, Train_Loss=0.209]\n","100%|██████████| 1/1 [00:00<00:00,  6.73it/s, Epoch=19, LR=1.46e-6, Valid_Loss=0.0763]\n"]},{"output_type":"stream","name":"stdout","text":["F1-Score: 0.0\n","f1: 0.0\n","\u001b[34mValidation Acc Improved (0.0 ---> 0.0)\n","Model Saved\u001b[0m\n","\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:00<00:00,  2.27it/s, Epoch=20, LR=8.28e-7, Train_Loss=0.222]\n","100%|██████████| 1/1 [00:00<00:00,  6.24it/s, Epoch=20, LR=8.28e-7, Valid_Loss=0.0762]\n"]},{"output_type":"stream","name":"stdout","text":["F1-Score: 0.0\n","f1: 0.0\n","\u001b[34mValidation Acc Improved (0.0 ---> 0.0)\n","Model Saved\u001b[0m\n","\n","Training complete in 0h 1m 38s\n","Best Acc: 0.0000\n","\n","\u001b[33m====== Fold: 3 ======\u001b[0m\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at microsoft/mdeberta-v3-base were not used when initializing DebertaV2Model: ['mask_predictions.dense.weight', 'mask_predictions.classifier.bias', 'mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.dense.bias', 'mask_predictions.classifier.weight', 'lm_predictions.lm_head.bias', 'mask_predictions.LayerNorm.weight', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.LayerNorm.bias']\n","- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["[INFO] Using GPU: A100-SXM4-40GB\n","\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:00<00:00,  2.30it/s, Epoch=1, LR=1.99e-5, Train_Loss=0.989]\n","100%|██████████| 1/1 [00:00<00:00,  6.84it/s, Epoch=1, LR=1.99e-5, Valid_Loss=0.952]\n"]},{"output_type":"stream","name":"stdout","text":["F1-Score: 0.15384615384615385\n","f1: 0.15384615384615385\n","\u001b[34mValidation Acc Improved (0.0 ---> 0.15384615384615385)\n","Model Saved\u001b[0m\n","\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:00<00:00,  2.23it/s, Epoch=2, LR=1.96e-5, Train_Loss=0.933]\n","100%|██████████| 1/1 [00:00<00:00,  5.88it/s, Epoch=2, LR=1.96e-5, Valid_Loss=0.922]\n"]},{"output_type":"stream","name":"stdout","text":["F1-Score: 0.15384615384615385\n","f1: 0.15384615384615385\n","\u001b[34mValidation Acc Improved (0.0 ---> 0.15384615384615385)\n","Model Saved\u001b[0m\n","\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:00<00:00,  2.30it/s, Epoch=3, LR=1.92e-5, Train_Loss=0.927]\n","100%|██████████| 1/1 [00:00<00:00,  6.75it/s, Epoch=3, LR=1.92e-5, Valid_Loss=0.896]\n"]},{"output_type":"stream","name":"stdout","text":["F1-Score: 0.15384615384615385\n","f1: 0.15384615384615385\n","\u001b[34mValidation Acc Improved (0.0 ---> 0.15384615384615385)\n","Model Saved\u001b[0m\n","\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:00<00:00,  2.27it/s, Epoch=4, LR=1.85e-5, Train_Loss=0.913]\n","100%|██████████| 1/1 [00:00<00:00,  6.76it/s, Epoch=4, LR=1.85e-5, Valid_Loss=0.871]\n"]},{"output_type":"stream","name":"stdout","text":["F1-Score: 0.15384615384615385\n","f1: 0.15384615384615385\n","\u001b[34mValidation Acc Improved (0.0 ---> 0.15384615384615385)\n","Model Saved\u001b[0m\n","\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:00<00:00,  2.23it/s, Epoch=5, LR=1.78e-5, Train_Loss=0.904]\n","100%|██████████| 1/1 [00:00<00:00,  6.58it/s, Epoch=5, LR=1.78e-5, Valid_Loss=0.843]\n"]},{"output_type":"stream","name":"stdout","text":["F1-Score: 0.15384615384615385\n","f1: 0.15384615384615385\n","\u001b[34mValidation Acc Improved (0.0 ---> 0.15384615384615385)\n","Model Saved\u001b[0m\n","\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:00<00:00,  2.22it/s, Epoch=6, LR=1.68e-5, Train_Loss=0.842]\n","100%|██████████| 1/1 [00:00<00:00,  6.48it/s, Epoch=6, LR=1.68e-5, Valid_Loss=0.811]\n"]},{"output_type":"stream","name":"stdout","text":["F1-Score: 0.15384615384615385\n","f1: 0.15384615384615385\n","\u001b[34mValidation Acc Improved (0.0 ---> 0.15384615384615385)\n","Model Saved\u001b[0m\n","\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:00<00:00,  2.30it/s, Epoch=7, LR=1.58e-5, Train_Loss=0.835]\n","100%|██████████| 1/1 [00:00<00:00,  6.58it/s, Epoch=7, LR=1.58e-5, Valid_Loss=0.773]\n"]},{"output_type":"stream","name":"stdout","text":["F1-Score: 0.15384615384615385\n","f1: 0.15384615384615385\n","\u001b[34mValidation Acc Improved (0.0 ---> 0.15384615384615385)\n","Model Saved\u001b[0m\n","\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:00<00:00,  2.34it/s, Epoch=8, LR=1.46e-5, Train_Loss=0.775]\n","100%|██████████| 1/1 [00:00<00:00,  6.40it/s, Epoch=8, LR=1.46e-5, Valid_Loss=0.722]\n"]},{"output_type":"stream","name":"stdout","text":["F1-Score: 0.15384615384615385\n","f1: 0.15384615384615385\n","\u001b[34mValidation Acc Improved (0.0 ---> 0.15384615384615385)\n","Model Saved\u001b[0m\n","\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:00<00:00,  2.24it/s, Epoch=9, LR=1.33e-5, Train_Loss=0.711]\n","100%|██████████| 1/1 [00:00<00:00,  6.81it/s, Epoch=9, LR=1.33e-5, Valid_Loss=0.639]\n"]},{"output_type":"stream","name":"stdout","text":["F1-Score: 0.6666666666666666\n","f1: 0.6666666666666666\n","\u001b[34mValidation Acc Improved (0.0 ---> 0.6666666666666666)\n","Model Saved\u001b[0m\n","\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:00<00:00,  2.29it/s, Epoch=10, LR=1.2e-5, Train_Loss=0.641]\n","100%|██████████| 1/1 [00:00<00:00,  6.61it/s, Epoch=10, LR=1.2e-5, Valid_Loss=0.49]\n"]},{"output_type":"stream","name":"stdout","text":["F1-Score: 1.0\n","f1: 1.0\n","\u001b[34mValidation Acc Improved (0.0 ---> 1.0)\n","Model Saved\u001b[0m\n","\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:00<00:00,  2.29it/s, Epoch=11, LR=1.07e-5, Train_Loss=0.552]\n","100%|██████████| 1/1 [00:00<00:00,  6.56it/s, Epoch=11, LR=1.07e-5, Valid_Loss=0.314]\n"]},{"output_type":"stream","name":"stdout","text":["F1-Score: 0.0\n","f1: 0.0\n","\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:00<00:00,  2.47it/s, Epoch=12, LR=9.32e-6, Train_Loss=0.335]\n","100%|██████████| 1/1 [00:00<00:00,  6.78it/s, Epoch=12, LR=9.32e-6, Valid_Loss=0.24]\n"]},{"output_type":"stream","name":"stdout","text":["F1-Score: 0.0\n","f1: 0.0\n","\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:00<00:00,  2.43it/s, Epoch=13, LR=7.97e-6, Train_Loss=0.287]\n","100%|██████████| 1/1 [00:00<00:00,  6.69it/s, Epoch=13, LR=7.97e-6, Valid_Loss=0.259]\n"]},{"output_type":"stream","name":"stdout","text":["F1-Score: 0.0\n","f1: 0.0\n","\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:00<00:00,  2.47it/s, Epoch=14, LR=6.65e-6, Train_Loss=0.232]\n","100%|██████████| 1/1 [00:00<00:00,  6.33it/s, Epoch=14, LR=6.65e-6, Valid_Loss=0.279]\n"]},{"output_type":"stream","name":"stdout","text":["F1-Score: 0.0\n","f1: 0.0\n","\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:00<00:00,  2.41it/s, Epoch=15, LR=5.4e-6, Train_Loss=0.205]\n","100%|██████████| 1/1 [00:00<00:00,  6.72it/s, Epoch=15, LR=5.4e-6, Valid_Loss=0.285]\n"]},{"output_type":"stream","name":"stdout","text":["F1-Score: 0.0\n","f1: 0.0\n","\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:00<00:00,  2.34it/s, Epoch=16, LR=4.23e-6, Train_Loss=0.287]\n","100%|██████████| 1/1 [00:00<00:00,  6.66it/s, Epoch=16, LR=4.23e-6, Valid_Loss=0.287]\n"]},{"output_type":"stream","name":"stdout","text":["F1-Score: 0.0\n","f1: 0.0\n","\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:00<00:00,  2.38it/s, Epoch=17, LR=3.17e-6, Train_Loss=0.232]\n","100%|██████████| 1/1 [00:00<00:00,  6.77it/s, Epoch=17, LR=3.17e-6, Valid_Loss=0.289]\n"]},{"output_type":"stream","name":"stdout","text":["F1-Score: 0.0\n","f1: 0.0\n","\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:00<00:00,  2.46it/s, Epoch=18, LR=2.24e-6, Train_Loss=0.264]\n","100%|██████████| 1/1 [00:00<00:00,  6.13it/s, Epoch=18, LR=2.24e-6, Valid_Loss=0.29]\n"]},{"output_type":"stream","name":"stdout","text":["F1-Score: 0.0\n","f1: 0.0\n","\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:00<00:00,  2.40it/s, Epoch=19, LR=1.46e-6, Train_Loss=0.183]\n","100%|██████████| 1/1 [00:00<00:00,  6.79it/s, Epoch=19, LR=1.46e-6, Valid_Loss=0.29]\n"]},{"output_type":"stream","name":"stdout","text":["F1-Score: 0.0\n","f1: 0.0\n","\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:00<00:00,  2.41it/s, Epoch=20, LR=8.28e-7, Train_Loss=0.255]\n","100%|██████████| 1/1 [00:00<00:00,  6.76it/s, Epoch=20, LR=8.28e-7, Valid_Loss=0.291]\n"]},{"output_type":"stream","name":"stdout","text":["F1-Score: 0.0\n","f1: 0.0\n","\n","Training complete in 0h 1m 3s\n","Best Acc: 0.0000\n","\n","['models/bert-2022-11-13-16-28/model-fold0.bin', 'models/bert-2022-11-13-16-28/model-fold1.bin', 'models/bert-2022-11-13-16-28/model-fold2.bin', 'models/bert-2022-11-13-16-28/model-fold3.bin']\n","\u001b[33m====== Fold: 0 ======\u001b[0m\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at microsoft/mdeberta-v3-base were not used when initializing DebertaV2Model: ['mask_predictions.dense.weight', 'mask_predictions.classifier.bias', 'mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.dense.bias', 'mask_predictions.classifier.weight', 'lm_predictions.lm_head.bias', 'mask_predictions.LayerNorm.weight', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.LayerNorm.bias']\n","- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Getting predictions for model 1\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:00<00:00,  6.53it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[33m====== Fold: 1 ======\u001b[0m\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at microsoft/mdeberta-v3-base were not used when initializing DebertaV2Model: ['mask_predictions.dense.weight', 'mask_predictions.classifier.bias', 'mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.dense.bias', 'mask_predictions.classifier.weight', 'lm_predictions.lm_head.bias', 'mask_predictions.LayerNorm.weight', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.LayerNorm.bias']\n","- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Getting predictions for model 1\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:00<00:00,  6.22it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[33m====== Fold: 2 ======\u001b[0m\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at microsoft/mdeberta-v3-base were not used when initializing DebertaV2Model: ['mask_predictions.dense.weight', 'mask_predictions.classifier.bias', 'mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.dense.bias', 'mask_predictions.classifier.weight', 'lm_predictions.lm_head.bias', 'mask_predictions.LayerNorm.weight', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.LayerNorm.bias']\n","- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Getting predictions for model 1\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:00<00:00,  6.59it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[33m====== Fold: 3 ======\u001b[0m\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at microsoft/mdeberta-v3-base were not used when initializing DebertaV2Model: ['mask_predictions.dense.weight', 'mask_predictions.classifier.bias', 'mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.dense.bias', 'mask_predictions.classifier.weight', 'lm_predictions.lm_head.bias', 'mask_predictions.LayerNorm.weight', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.LayerNorm.bias']\n","- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Getting predictions for model 1\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:00<00:00,  6.02it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Val F1-Score:  [0.0, 0.0, 0.0, 1.0]\n","CV F1-Score:  0.5\n","Val f1:  [0.0, 0.0, 0.0, 1.0]\n","CV f1:  0.5\n"]}],"source":["#!/usr/bin/env python\n","# coding: utf-8\n","\n","# ### 参考notebook\n","# https://www.kaggle.com/code/debarshichanda/pytorch-w-b-jigsaw-starter\n","\n","# In[1]:\n","\n","\n","# !nvidia-smi\n","\n","\n","# In[2]:\n","\n","\n","# !pip install --upgrade wandb\n","\n","\n","# In[3]:\n","\n","\n","# !pip install GPUtil\n","# !pip install transformers==4.12.2\n","# !pip install fugashi\n","# !pip install mecab-python3\n","# !pip install ipadic\n","\n","# !pip install colorama\n","\n","\n","# In[4]:\n","\n","\n","import os\n","import gc\n","import copy\n","import time\n","import random\n","import string\n","import sys\n","\n","import datetime\n","from datetime import datetime, timedelta, timezone\n","\n","# For data manipulation\n","import numpy as np\n","import pandas as pd\n","\n","# Pytorch Imports\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.optim import lr_scheduler\n","from torch.utils.data import Dataset, DataLoader\n","import torch.nn.functional as F\n","\n","# Utils\n","from tqdm import tqdm\n","from collections import defaultdict\n","\n","# Sklearn Imports\n","from sklearn.metrics import mean_squared_error\n","from sklearn.model_selection import StratifiedKFold, KFold\n","\n","# For Transformer Models\n","from transformers import AutoConfig, AutoTokenizer, AutoModel, AdamW\n","\n","# For colored terminal text\n","from colorama import Fore, Back, Style\n","b_ = Fore.BLUE\n","y_ = Fore.YELLOW\n","sr_ = Style.RESET_ALL\n","\n","# Suppress warnings\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","# For descriptive error messages\n","os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n","\n","import pickle\n","import re\n","import unicodedata\n","\n","import regex\n","import scipy as sp\n","from sklearn.metrics import f1_score\n","from sklearn.metrics import log_loss, accuracy_score\n","from sklearn.model_selection import StratifiedKFold\n","import torch\n","from torch.utils.data import TensorDataset, random_split\n","from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n","from transformers import BertJapaneseTokenizer, BertForSequenceClassification, AdamW, T5Tokenizer\n","from transformers import get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup\n","\n","sys.path.append(\"/content/drive/MyDrive/ColabNotebooks/nishika/hate_speech/fake_1th/roberta_japanese\")\n","from tokenization_roberta_japanese import RobertaJapaneseTokenizer\n","\n","warnings.filterwarnings('ignore')\n","\n","\n","# In[5]:\n","\n","\n","# import wandb\n","# wandb.login()\n","\n","\n","# In[6]:\n","\n","\n","def id_generator(size=12, chars=string.ascii_lowercase + string.digits):\n","    return ''.join(random.SystemRandom().choice(chars) for _ in range(size))\n","\n","JST = timezone(timedelta(hours=+9), 'JST')\n","now = datetime.now(JST)\n","current_time = now.strftime(\"%Y-%m-%d-%H-%M\", )\n","\n","HASH_NAME = \"Fakenews-\" + current_time\n","\n","print(HASH_NAME)\n","\n","\n","# In[7]:\n","\n","\n","# from google.colab import drive \n","# drive.mount('/content/drive')\n","\n","\n","# In[8]:\n","\n","\n","ROOT = \"../../cpt-fakenews\"\n","# CUR_DIR = ROOT+\"/baseline/code\"\n","# %cd $CUR_DIR\n","\n","\n","# In[9]:\n","\n","\n","CONFIG = {\"seed\": 2022,\n","          \"epochs\": 8, # 20\n","          \"model_name\": r'microsoft/mdeberta-v3-base',  # r'cl-tohoku/bert-base-japanese-v2' cl-tohoku/bert-base-japanese-whole-word-masking\n","          \"train_batch_size\": 32,\n","          \"valid_batch_size\": 64,\n","          \"max_length\": 100,\n","          \"learning_rate\": 2e-5,\n","          \"scheduler\": 'cosine',\n","          \"num_cycles\": 0.5,\n","          \"num_warmup_steps\": 0,\n","          \"min_lr\": 1e-7,\n","          \"T_max\": 500,\n","          \"weight_decay\": 0.01,\n","          \"max_grad_norm\" :1.0,\n","          \"n_accumulate\": 1,\n","          \"num_classes\": 2,\n","          \"n_fold\": 4,\n","          \"device\": torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\"),\n","          \"hash_name\": HASH_NAME,\n","          \"dropout\" : 0.2,\n","          \"debug\" : True\n","          }\n","\n","if CONFIG['model_name'] == \"rinna/japanese-roberta-base\":\n","    CONFIG[\"tokenizer\"] = T5Tokenizer.from_pretrained(CONFIG['model_name'])\n","    CONFIG[\"tokenizer\"].do_lower_case = True\n","    print(\"Vocab size: \", CONFIG[\"tokenizer\"].vocab_size)\n","elif CONFIG['model_name'] == \"cl-tohoku/roberta-base-japanese\":\n","    CONFIG[\"tokenizer\"] = RobertaJapaneseTokenizer.from_pretrained(CONFIG['model_name'])\n","else:\n","    CONFIG[\"tokenizer\"] = AutoTokenizer.from_pretrained(CONFIG['model_name'])\n","CONFIG['group'] = f'{HASH_NAME}-Baseline'\n","\n","\n","# In[10]:\n","\n","\n","def set_seed(seed=42):\n","    '''Sets the seed of the entire notebook so results are the same every time we run.\n","    This is for REPRODUCIBILITY.'''\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    # When running on the CuDNN backend, two further options must be set\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = False\n","    # Set a fixed value for the hash seed\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    \n","set_seed(seed=42)\n","\n","\n","# In[11]:\n","\n","\n","df = pd.read_csv('/content/drive/MyDrive/input/nishika/hate_speech/train.csv')\n","print(df.head())\n","\n","if CONFIG['debug']:\n","    df = df.head(50) \n","\n","# In[12]:\n","\n","\n","df[\"label\"].value_counts()\n","\n","\n","# # <span><h1 style = \"font-family: garamond; font-size: 40px; font-style: normal; letter-spcaing: 3px; background-color: #f6f5f5; color :#fe346e; border-radius: 100px 100px; text-align:center\">Create Folds</h1></span>\n","\n","# In[13]:\n","\n","\n","skf = StratifiedKFold(n_splits=CONFIG['n_fold'], shuffle=True, random_state=CONFIG['seed'])\n","\n","for fold, ( _, val_) in enumerate(skf.split(X=df, y=df[\"label\"])):\n","    df.loc[val_ , \"kfold\"] = int(fold)\n","    \n","df[\"kfold\"] = df[\"kfold\"].astype(int)\n","print(df.head())\n","\n","\n","# In[14]:\n","\n","\n","class FakenewsDataset(Dataset):\n","    def __init__(self, df, tokenizer, max_length):\n","        self.df = df\n","        self.max_len = max_length\n","        self.tokenizer = tokenizer\n","        self.text = df['text'].values\n","        self.target = df['label'].values\n","        \n","    def __len__(self):\n","        return len(self.df)\n","    \n","    def __getitem__(self, index):\n","    \n","        text = self.text[index]\n","        inputs_text = self.tokenizer.encode_plus(\n","                                text,\n","                                truncation=True,\n","                                add_special_tokens=True,\n","                                max_length=self.max_len,\n","                                padding='max_length'\n","                            )\n","    \n","        target = self.target[index]\n","        \n","        onehot_t = np.zeros(CONFIG[\"num_classes\"], dtype=np.float32) + 0.0025 ### Label smoothing\n","        onehot_t[target] = 0.995\n","        \n","        ids = inputs_text['input_ids']\n","        mask = inputs_text['attention_mask']\n","        \n","        # print(len(ids))\n","        # print(ids)\n","        return {\n","            'ids': torch.tensor(ids, dtype=torch.long),\n","            'mask': torch.tensor(mask, dtype=torch.long),\n","            'target': torch.tensor(onehot_t, dtype=torch.float)\n","        }\n","\n","# train_dataset = FakenewsDataset(df, tokenizer=CONFIG['tokenizer'], max_length=CONFIG['max_length'])\n","# print(train_dataset[0])\n","\n","# In[15]:\n","\n","\n","class FakenewsModel(nn.Module):\n","    def __init__(self, cfg, config_path=None):\n","        super(FakenewsModel, self).__init__()\n","        if config_path is None:\n","            self.config = AutoConfig.from_pretrained(cfg[\"model_name\"], output_hidden_states=False)\n","        else:\n","            self.config = torch.load(config_path)\n","            \n","        self.model = AutoModel.from_pretrained(cfg[\"model_name\"], config=self.config)\n","        self.drop = nn.Dropout(p=cfg[\"dropout\"])\n","        self.fc = nn.Linear(self.config.hidden_size, cfg['num_classes'])\n","        self.sigmoid = nn.Sigmoid()\n","        \n","    def forward(self, ids, mask):        \n","        out = self.model(input_ids=ids,attention_mask=mask,\n","                         output_hidden_states=False)\n","        out = self.drop(out.last_hidden_state[:, 0, :])\n","        outputs = self.fc(out)\n","        outputs = self.sigmoid(outputs)\n","        \n","        return outputs.squeeze()\n","\n","\n","# In[16]:\n","\n","\n","def criterion(outputs, targets):\n","    loss_f = nn.BCELoss()\n","    \"\"\"\n","    print(\"output\",outputs.shape, 'targets',targets.shape)\n","    print(outputs)\n","    print(targets)\n","    \"\"\"\n","    return loss_f(outputs,targets)\n","\n","\n","# In[17]:\n","\n","\n","def train_one_epoch(model, optimizer, scheduler, dataloader, device, epoch):\n","    model.train()\n","    \n","    dataset_size = 0\n","    running_loss = 0.0\n","    \n","    bar = tqdm(enumerate(dataloader), total=len(dataloader))\n","    for step, data in bar:\n","        ids = data['ids'].to(device, dtype = torch.long)\n","        mask = data['mask'].to(device, dtype = torch.long)\n","        targets = data['target'].to(device, dtype=torch.float)\n","        \n","        batch_size = ids.size(0)\n","\n","        outputs = model(ids, mask)\n","        \n","        loss = criterion(outputs, targets)\n","        loss = loss / CONFIG['n_accumulate']\n","        loss.backward()\n","    \n","        if (step + 1) % CONFIG['n_accumulate'] == 0:\n","            optimizer.step()\n","\n","            # zero the parameter gradients\n","            optimizer.zero_grad()\n","\n","            if scheduler is not None:\n","                scheduler.step()\n","                \n","        running_loss += (loss.item() * batch_size)\n","        dataset_size += batch_size\n","        \n","        epoch_loss = running_loss / dataset_size\n","        \n","        bar.set_postfix(Epoch=epoch, Train_Loss=epoch_loss,\n","                        LR=scheduler.get_lr()[0])\n","    gc.collect()\n","    \n","    return epoch_loss\n","\n","\n","# In[18]:\n","\n","\n","@torch.no_grad()\n","def valid_one_epoch(model, dataloader, device, epoch):\n","    model.eval()\n","    \n","    dataset_size = 0\n","    running_loss = 0.0\n","    \n","    predictions = []\n","    labels = []\n","    bar = tqdm(enumerate(dataloader), total=len(dataloader))\n","    for step, data in bar:        \n","        ids = data['ids'].to(device, dtype = torch.long)\n","        mask = data['mask'].to(device, dtype = torch.long)\n","        targets = data['target'].to(device, dtype=torch.float)\n","        \n","        batch_size = ids.size(0)\n","\n","        outputs = model(ids, mask)\n","        \n","        loss = criterion(outputs, targets)\n","        \n","        running_loss += (loss.item() * batch_size)\n","        dataset_size += batch_size\n","        \n","        epoch_loss = running_loss / dataset_size\n","        \n","        bar.set_postfix(Epoch=epoch, Valid_Loss=epoch_loss,\n","                        LR=optimizer.param_groups[0]['lr'])\n","        \n","        preds = np.argmax(outputs.detach().cpu().numpy(), axis=1)\n","        predictions.append(preds)\n","        labels.append(np.argmax(targets.cpu().numpy(), axis=1))\n","    \n","    gc.collect()\n","    \n","    predictions = np.concatenate(predictions, 0)\n","    labels = np.concatenate(labels, 0)\n","    \n","    return epoch_loss, predictions, labels\n","\n","\n","# In[42]:\n","\n","\n","def run_training(model, optimizer, scheduler, device, num_epochs, fold, savepath):\n","    # To automatically log gradients\n","    # wandb.watch(model, log_freq=100)\n","    \n","    if torch.cuda.is_available():\n","        print(\"[INFO] Using GPU: {}\\n\".format(torch.cuda.get_device_name()))\n","    \n","    start = time.time()\n","    best_model_wts = copy.deepcopy(model.state_dict())\n","    best_epoch_loss = np.inf\n","    best_f1 = 0.0\n","    best_acc = 0.0\n","    history = defaultdict(list)\n","    \n","    for epoch in range(1, num_epochs + 1): \n","        gc.collect()\n","        train_epoch_loss = train_one_epoch(model, optimizer, scheduler, \n","                                           dataloader=train_loader, \n","                                           device=CONFIG['device'], epoch=epoch)\n","        \n","        val_epoch_loss, predictions, labels = valid_one_epoch(model, valid_loader, device=CONFIG['device'], \n","                                         epoch=epoch)\n","    \n","        history['Train Loss'].append(train_epoch_loss)\n","        history['Valid Loss'].append(val_epoch_loss)\n","        \n","        # print(predictions.shape)\n","        # print(labels.shape)\n","        f1 = f1_score(labels, predictions)\n","        print(f\"F1-Score: {f1}\")\n","        accuracy = accuracy_score(labels, predictions)\n","        print(f\"f1: {f1}\")\n","    \n","        # Log the metrics\n","#         wandb.log({\"Train Loss\": train_epoch_loss})\n","#         wandb.log({\"Valid Loss\": val_epoch_loss})\n","        \n","        # deep copy the model\n","        if best_f1 <= f1:\n","            print(f\"{b_}Validation Acc Improved ({best_acc} ---> {f1})\")\n","            best_f1 = f1\n","            # run.summary[\"Best Loss\"] = best_epoch_loss\n","            best_model_wts = copy.deepcopy(model.state_dict())\n","            #PATH = f\"Loss-Fold-{fold}.bin\"    ####ここのPATHは変えよう\n","            PATH = os.path.join(savepath , f\"model-fold{fold}.bin\")\n","            torch.save(model.state_dict(), PATH)\n","            # Save a model file from the current directory\n","            print(f\"Model Saved{sr_}\")\n","            \n","        print()\n","    \n","    end = time.time()\n","    time_elapsed = end - start\n","    print('Training complete in {:.0f}h {:.0f}m {:.0f}s'.format(\n","        time_elapsed // 3600, (time_elapsed % 3600) // 60, (time_elapsed % 3600) % 60))\n","    print(\"Best Acc: {:.4f}\".format(best_acc))\n","    \n","    # load best model weights\n","    model.load_state_dict(best_model_wts)\n","    \n","    return model, history\n","\n","\n","# In[43]:\n","\n","\n","def prepare_loaders(f_train, df_valid):\n","    train_dataset = FakenewsDataset(df_train, tokenizer=CONFIG['tokenizer'], max_length=CONFIG['max_length'])\n","    valid_dataset = FakenewsDataset(df_valid, tokenizer=CONFIG['tokenizer'], max_length=CONFIG['max_length'])\n","\n","    train_loader = DataLoader(train_dataset, batch_size=CONFIG['train_batch_size'], \n","                              num_workers=2, shuffle=True, pin_memory=True, drop_last=True)\n","    valid_loader = DataLoader(valid_dataset, batch_size=CONFIG['valid_batch_size'], \n","                              num_workers=2, shuffle=False, pin_memory=True)\n","    \n","    return train_loader, valid_loader\n","\n","\n","# In[44]:\n","\n","\n","def fetch_scheduler(optimizer):\n","    if CONFIG['scheduler'] == 'CosineAnnealingLR':\n","        scheduler = lr_scheduler.CosineAnnealingLR(optimizer,T_max=CONFIG['T_max'], \n","                                                   eta_min=CONFIG['min_lr'])\n","    elif CONFIG['scheduler'] == 'CosineAnnealingWarmRestarts':\n","        scheduler = lr_scheduler.CosineAnnealingWarmRestarts(optimizer,T_0=CONFIG['T_0'], \n","                                                             eta_min=CONFIG['min_lr'])\n","    elif CONFIG['scheduler'] == None:\n","        return None\n","        \n","    return scheduler\n","\n","\n","def get_scheduler(cfg, optimizer, num_train_steps):\n","  cfg_scheduler = cfg[\"scheduler\"]\n","  num_warmup_steps = cfg[\"num_warmup_steps\"]\n","  if cfg_scheduler == 'linear':\n","    scheduler = get_linear_schedule_with_warmup(\n","      optimizer, num_warmup_steps=num_warmup_steps, num_training_steps=num_train_steps\n","    )\n","  elif cfg_scheduler == 'cosine':\n","      scheduler = get_cosine_schedule_with_warmup(\n","        optimizer, num_warmup_steps=num_warmup_steps, num_training_steps=num_train_steps, num_cycles=cfg[\"num_cycles\"]\n","      )\n","  return scheduler\n","\n","\n","# In[45]:\n","\n","\n","modelpath = f\"models/bert-{current_time}\"  \n","if not os.path.isdir(modelpath):\n","    os.makedirs(modelpath)\n","\n","for fold in range(0, CONFIG['n_fold']):\n","    print(f\"{y_}====== Fold: {fold} ======{sr_}\")\n","#     run = wandb.init(project='Fakenews', \n","#                      config=CONFIG,\n","#                      job_type='Train',\n","#                      group=CONFIG['group'],\n","#                      tags=['bert', f'{HASH_NAME}', 'bceloss'],\n","#                      name=f'{HASH_NAME}-fold-{fold}',\n","#                      anonymous='must')\n","    \n","    # Create Dataloaders\n","    df_train = df[df.kfold != fold].reset_index(drop=True)\n","    df_valid = df[df.kfold == fold].reset_index(drop=True)\n","    \n","    train_loader, valid_loader = prepare_loaders(df_train, df_valid)\n","    \n","    model = FakenewsModel(CONFIG)\n","    model.to(CONFIG['device'])\n","    \n","    # Define Optimizer and Scheduler\n","    optimizer = AdamW(model.parameters(), lr=CONFIG['learning_rate'], weight_decay=CONFIG['weight_decay'])\n","    # scheduler = fetch_scheduler(optimizer)\n","    num_train_steps = int(len(df_train) / CONFIG[\"train_batch_size\"] * CONFIG['epochs'])\n","    scheduler = get_scheduler(CONFIG, optimizer, num_train_steps)\n","    \n","    model, history = run_training(model, optimizer, scheduler,\n","                                  device=CONFIG['device'],\n","                                  num_epochs=CONFIG['epochs'],\n","                                  fold=fold,\n","                                  savepath=modelpath)\n","    \n","    # run.finish()\n","    \n","    del model, history, train_loader, valid_loader\n","    _ = gc.collect()\n","    print()\n","\n","\n","# ## Validation\n","\n","# In[47]:\n","\n","\n","# get_ipython().system('ls $modelpath')\n","\n","\n","# In[50]:\n","\n","\n","from glob import glob\n","MODEL_PATHS = glob(f'{modelpath}/*.bin')\n","MODEL_PATHS.sort()\n","\n","\n","# In[51]:\n","\n","\n","print(MODEL_PATHS)\n","\n","\n","# In[52]:\n","\n","\n","@torch.no_grad()\n","def valid_fn(model, dataloader, device):\n","    model.eval()\n","    \n","    dataset_size = 0\n","    running_loss = 0.0\n","    \n","    PREDS = []\n","    \n","    bar = tqdm(enumerate(dataloader), total=len(dataloader))\n","    for step, data in bar:\n","        ids = data['ids'].to(device, dtype = torch.long)\n","        mask = data['mask'].to(device, dtype = torch.long)\n","        \n","        outputs = model(ids, mask)\n","        \n","        #PREDS.append(outputs.view(-1).cpu().detach().numpy()) \n","        PREDS.append(outputs.cpu().detach().numpy()) \n","\n","    PREDS = np.concatenate(PREDS)\n","    gc.collect()\n","    \n","    return PREDS\n","\n","\n","# In[53]:\n","\n","\n","def inference(model_paths, dataloader, device):\n","    final_preds = []\n","    for i, path in enumerate(model_paths):\n","        model = FakenewsModel(CONFIG)\n","        model.to(CONFIG['device'])\n","        model.load_state_dict(torch.load(path))\n","        \n","        print(f\"Getting predictions for model {i+1}\")\n","        preds = valid_fn(model, dataloader, device)\n","        final_preds.append(preds)\n","    \n","    final_preds = np.array(final_preds)\n","    final_preds = np.mean(final_preds, axis=0)\n","    return final_preds\n","\n","\n","# In[54]:\n","\n","\n","def get_labels_frompred(out, multi=False):\n","    print(out)\n","    o = (-out).argsort(1) \n","    preds = int(o[0][0].cpu().numpy())\n","    print(preds)\n","\n","    return preds\n","\n","\n","# In[55]:\n","\n","\n","from sklearn.metrics import f1_score\n","from sklearn.metrics import accuracy_score\n","\n","fold_f1scores = []\n","fold_accuracyscores = []\n","\n","oof_df = pd.DataFrame()\n","predictions = []\n","targets = []\n","for fold in range(0, CONFIG['n_fold']):\n","    print(f\"{y_}====== Fold: {fold} ======{sr_}\")\n","    \n","    train = df[df.kfold != fold].reset_index(drop=True)\n","    valid = df[df.kfold == fold].reset_index(drop=True)\n","    \n","    train_loader, valid_loader = prepare_loaders(train, valid)\n","\n","    valid = df[df[\"kfold\"]==fold]\n","\n","    out = inference([MODEL_PATHS[fold]], valid_loader, CONFIG['device'])\n","    \n","    preds = np.argmax(out, axis=1)\n","    valid[\"preds\"] = preds\n","    predictions.append(preds)\n","    targets.append(valid[\"label\"].values)\n","    \n","    fold_f1scores.append(f1_score(valid[\"label\"].values, valid[\"preds\"].values))\n","    fold_accuracyscores.append(accuracy_score(valid[\"label\"].values, valid[\"preds\"].values))\n","    \n","    # print(out.shape)\n","    valid[\"preds\"] = out[:, 0]\n","    valid[\"preds2\"] = out[:, 1]\n","    oof_df = pd.concat([oof_df, valid])\n","    \n","oof_df = oof_df.reset_index(drop=True)\n","oof_df.to_csv('/content/drive/MyDrive/output/nishika/hate_speech/oof_df.csv', index=False)\n","\n","# In[56]:\n","\n","predictions = np.concatenate(predictions, 0)\n","targets = np.concatenate(targets, 0)\n","\n","print(\"Val F1-Score: \", fold_f1scores)\n","print(\"CV F1-Score: \", f1_score(targets, predictions))\n","\n","\n","# In[57]:\n","\n","\n","print(\"Val f1: \", fold_f1scores)\n","print(\"CV f1: \", f1_score(targets, predictions))\n","\n","# In[ ]:\n","\n","\n","\n","\n"]},{"cell_type":"code","source":[],"metadata":{"id":"kZf6vKtHvuvx","executionInfo":{"status":"ok","timestamp":1668324907699,"user_tz":-540,"elapsed":6,"user":{"displayName":"大橋幸記","userId":"14481296101370409019"}}},"execution_count":3,"outputs":[]}]}